{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOH/0z7fw0enQaAAxPCvWTB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moorthy-dnkkw/MACHINE-LEARNING-ITA0624/blob/main/3_ID3_decision_tree_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, attribute=None, value=None, results=None, true_branch=None,\n",
        "                 false_branch=None):\n",
        "        self.attribute, self.value, self.results, self.true_branch, self.false_branch = attribute, value, results, \\\n",
        "                                                                                       true_branch, false_branch\n",
        "def build_tree(rows):\n",
        "    if not rows:\n",
        "        return Node()\n",
        "    # Check if all rows in the current subset belong to the same class\n",
        "    if len(set(row[-1] for row in rows)) == 1:\n",
        "        return Node(results=rows[0][-1])\n",
        "\n",
        "    num_attributes = len(rows[0]) - 1\n",
        "    best_attribute = max(range(num_attributes), key=lambda col: information_gain(rows, col))\n",
        "\n",
        "    true_rows = [row for row in rows if row[best_attribute] == 'Yes']\n",
        "    false_rows = [row for row in rows if row[best_attribute] == 'No']\n",
        "\n",
        "    true_branch = build_tree(true_rows)\n",
        "    false_branch = build_tree(false_rows)\n",
        "\n",
        "    return Node(attribute=best_attribute, value=rows[0][best_attribute], true_branch=true_branch,\n",
        "                false_branch=false_branch)\n",
        "\n",
        "def information_gain(rows, col):\n",
        "    total_entropy = entropy(rows)\n",
        "    values = set(row[col] for row in rows)\n",
        "    weighted_entropy = sum(len(list(filter(lambda row: row[col] == val, rows))) / len(rows) *\n",
        "                           entropy(list(filter(lambda row: row[col] == val, rows))) for val in values)\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "def entropy(rows):\n",
        "    from math import log2\n",
        "    counts = class_counts(rows)\n",
        "    if not counts: # Handle empty counts to avoid division by zero or log(0)\n",
        "        return 0\n",
        "    return -sum(count / len(rows) * log2(count / len(rows)) for count in counts.values() if count > 0)\n",
        "\n",
        "def class_counts(rows):\n",
        "    counts = {}\n",
        "    for row in rows:\n",
        "        label = row[-1]\n",
        "        counts[label] = counts.get(label, 0) + 1\n",
        "    return counts\n",
        "\n",
        "# Example dataset (you can modify this as needed)\n",
        "dataset = [\n",
        "    ['Sunny', 'Hot', 'High', 'Weak', 'No'],\n",
        "    ['Sunny', 'Hot', 'High', 'Strong', 'No'],\n",
        "    ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Mild', 'High', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Cool', 'Normal', 'Strong', 'No'],\n",
        "    ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],\n",
        "    ['Sunny', 'Mild', 'High', 'Weak', 'No'],\n",
        "    ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Mild', 'Normal', 'Weak', 'Yes']\n",
        "]\n",
        "\n",
        "# Build the decision tree\n",
        "tree = build_tree(dataset)\n",
        "\n",
        "# Print the decision tree\n",
        "def print_tree(node, indent=\"\"):\n",
        "    if node is None:\n",
        "        return\n",
        "    if node.results is not None:\n",
        "        print(indent + str(node.results))\n",
        "    else:\n",
        "        print(indent + f'Attribute {node.attribute} : {node.value}? ')\n",
        "        print(indent + '--> True:')\n",
        "        print_tree(node.true_branch, indent + '  ')\n",
        "        print(indent + '--> False:')\n",
        "        print_tree(node.false_branch, indent + '  ')\n",
        "\n",
        "print_tree(tree)\n",
        "\n",
        "# Classify a new sample\n",
        "new_sample = ['Sunny', 'Cool', 'High', 'Strong']\n",
        "current_node = tree\n",
        "while current_node.results is None and current_node.attribute is not None:\n",
        "    # Assuming the attribute value for 'Yes'/'No' branches is based on the attribute's specific value\n",
        "    # The original code used 'current_node.value' which was set as 'rows[0][best_attribute]' during tree building.\n",
        "    # This part of the classification logic needs to be revisited if 'value' is not meant to be static per node.\n",
        "    # For simplicity, assuming 'value' stores the specific value that leads to the true branch.\n",
        "    if new_sample[current_node.attribute] == current_node.value:\n",
        "        current_node = current_node.true_branch\n",
        "    else:\n",
        "        current_node = current_node.false_branch\n",
        "\n",
        "print(f\"\\nClassification result for {new_sample}: {current_node.results}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqElFevfv5-d",
        "outputId": "46ff8f06-a909-4bb0-bae8-97efff834763"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attribute 0 : Sunny? \n",
            "--> True:\n",
            "  Attribute None : None? \n",
            "  --> True:\n",
            "  --> False:\n",
            "--> False:\n",
            "  Attribute None : None? \n",
            "  --> True:\n",
            "  --> False:\n",
            "\n",
            "Classification result for ['Sunny', 'Cool', 'High', 'Strong']: None\n"
          ]
        }
      ]
    }
  ]
}